<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>且徐行</title>
    <link>https://blog.cc1234.cc/</link>
    <description>Recent content on 且徐行</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Feb 2021 23:44:37 +0200</lastBuildDate><atom:link href="https://blog.cc1234.cc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title> 你知道为什么 Java 会放弃偏向锁吗？ </title>
      <link>https://blog.cc1234.cc/posts/java-biased-locking/</link>
      <pubDate>Mon, 01 Feb 2021 23:45:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/java-biased-locking/</guid>
      <description>前言 随着 JDK15 的 Release，大量的新特性也和开发者们正式见面了（虽然不一定能用上&amp;hellip;&amp;hellip;），最引入注目的应该是 Text Block、Pattern Matching for instanceof (Second Preview) 等语法，因为这些特性是实实在在的影响了大家的开发体验。
而本文要讨论的却不是这些特性，而是关于废弃偏向锁的特性
 Disable and Deprecate Biased Locking（禁用和废弃偏向锁）  什么是偏向锁？ 在 Java 中，synchronized 关键字可以确保同一时间内只有一个线程进入临界区
 临界区：可以是整个方法体，也可以是方法的局部块
 在 JDK1.6 以后，JVM 特地针对 synchronized 进行了优化，引入了锁升级的概念，锁状态只可升级不可降级。
无锁 -&amp;gt; 偏向锁 -&amp;gt; 轻量级锁 -&amp;gt; 重量级锁 这里面我们主要关注偏向锁，它是 HotSpot VM 提供的一种用于减少锁开销的优化技术。
它的原理其实很简单：当线程进入第一次同步块以后，锁持有的对象头的偏向锁标记会被置为 1 ，如果未来一段时间内都是同一个线程访问该同步快的话就不用执行加锁操作了。
如果有另一个线程进入同步快的话，偏向锁就会升级到轻量级锁。
由此可以看出来如果同步块只有一个线程访问的话，偏向锁是可以带来显著的性能提升的。
既然如此，为何要废弃掉呢？
为什么要废弃？ 偏向锁带来的性能收益降低 在现今，偏向锁带来的性能提升远不如过去那么明显了。
在过去，旧的 Java 应用通常使用的都是比较老的集合库，比如 HashTable、Vector 等，这些集合库对应的方法都被 synchronized 修饰了。
如果在单线程使用这些集合库就会造成不必要的加锁操作，导致性能下降。
而新的无锁集合库，如 HashMap、ArrayList 等就没有这样的问题，如果是在多线程情况下，也有 ConcurrentHashMap、CopyOnWriteArrayList 等性能更好的线程安全的集合库。
所以在使用了新的集合库的情况下，偏向锁带来的收益会降低。
在多线程情况下，经常会使用到线程池，关闭偏向锁反而更好。</description>
    </item>
    
    <item>
      <title>我是如何开发了一款‘有人用’的开源软件</title>
      <link>https://blog.cc1234.cc/posts/how-to-develop-prettyzoo/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/how-to-develop-prettyzoo/</guid>
      <description>我是如何开发了一款“有人用”的开源软件 背景 PrettyZoo 是在去年国庆（2019 年）时开发的一个用于管理 Zookeeper 的桌面图形化工具，当时是因为在学习 Elastic-Job-Lite 框架的源码时涉及到了 Zookeeper，想着借助图形化工具去更直观的了解整个框架的设计，但在市面上却找不到一款符合自己期望的产品，那就只能自己动手丰衣足食了，这算是 PrettyZoo 诞生的初衷了。
其实我已经写过一篇文章来简单介绍过这个产品的研发历程（从 Java8 到 Java11 ： PrettyZoo 开发回顾（模块化在 GUI 中的实践））, 不过那篇文章主要侧重于产品的技术演进过程，这一篇文章是基于国庆重构后的全新版本来写的，记录了自己在这个重构的过程中各个阶段所做的事情，主要包括以下内容
 需求分析 原型设计 技术选型 架构设计 成品展示  需求分析 上一节的背景描述了我为什么要开发这样一款软件，而这一节的主要内容则是分析我想要开发的软件应该有的功能点。
该产品是用于管理 Zookeeper 数据，那么需求其实也需要围绕着 Zookeeper 的功能来分析，这就像为人作肖像画一样，得先去分析目标的特性。
我将分析后的需求整理成了下面的一个表格，并对功能的优先级、必要性做了标注
   需求 优先级 是否必须     连接创建 高 √   连接删除 高 √   节点展示 高 √   节点创建 高 √   节点删除 高 √   节点数据更新 高 √   递归操作支持 中 √   节点数据格式化（JSON、YAML） 低 ×   SSH Tunnel 支持 中 ×   ACL 支持 中 √   配置导入/导出 中 ×         当然实际的产品开发中还会去调查类同类产品，去参考它们的功能、设计等， 这方面我就略过了。</description>
    </item>
    
    <item>
      <title> Scala 与 Algebraic data type</title>
      <link>https://blog.cc1234.cc/posts/scala-adt/</link>
      <pubDate>Tue, 18 Aug 2020 20:50:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/scala-adt/</guid>
      <description>Scala 与 Algebraic data type 前言 在计算机编程中，数据类型（Data type）是一个基本概念，它是数据的一个属性，编译器或解释器可以根据该属性知道开发者打算如何使用该数据。
常见的数据类型有基本数据类型（Primitive data types）和组合数据类型（Composite Types）。
基本数据类型一般都是由编程语言内置的，比如 Integer、Float、Boolean、Char 等，而组合数据类型是从基本类型派生出来的，一个组合类型可以由基本类型组成，也可以由「其他组合类型 + 基本类型」组成。
比如在 Java 中通过 class 关键字就可以创建一个组合类型
public class User { private String name; // 姓名  private Integer age; // 年龄  private List&amp;lt;User&amp;gt; familyMembers; // 家庭成员 } Scala 中的 case class 也是组合类型
case class User(name: String, age: Integer, familyMembers: List[User]) 组合类型又可以分为很多种，而本文要聊的 Algebraic data type （以下简称 ADT 或 ADTs）就是其中之一
注：Algebraic data type，一般译作代数数据类型
Algebraic data type Algebraic data type 在函数式编程语言中是一个很常见的概念，要理解 ADT ，得先明白 Algebra（代数）的含义。</description>
    </item>
    
    <item>
      <title> Scala2 如何实现 Type class 派生</title>
      <link>https://blog.cc1234.cc/posts/typeclasses-deriving/</link>
      <pubDate>Sat, 15 Aug 2020 00:04:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/typeclasses-deriving/</guid>
      <description>Scala2 如何实现 Type class 派生 前言 本文主要是讨论在 Scala 中自动为 case class 派生 Type class 实例，如果你不知道什么是 Type class 的话，建议先阅读我的上一篇文章 《真的学不动了： 除了 class , 也该了解 Type classes 了》。
 本文使用的 Scala 版本为 2.13.2，Shapless 版本为 2.3.3
 提出问题 假设我现在有一个用于生成随机测试数据的 Type class，并且已经实现了 Int， Boolean 等基本类型的 Random 实例
trait Random[T] { def random(): T } object Random { def apply[T]()(implicit random: Random[T]) = random.random() implicit val intRandom = new Random[Int] { override def random(): Int = Math.</description>
    </item>
    
    <item>
      <title> VAVR：颠覆你的 Java 体验 </title>
      <link>https://blog.cc1234.cc/posts/vavr-1/</link>
      <pubDate>Sat, 25 Jul 2020 09:50:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/vavr-1/</guid>
      <description>VAVR：颠覆你的 Java 体验 何方神圣？ 众所周知， Java8 在一定程度上支持了函数式编程，但标准库提供的函数式 API 不是很完备和友好。
为了更好的进行函数式编程，我们就不得不借助于第三方库，而 VAVR 就是这方面的佼佼者，它可以有效减少代码量并提高代码质量。
VAVR 可不是默默无闻之辈，它的前身是发布于 2014 年的 Javaslang，目前在 github 上有着近 4k 的 star。
看到这儿，很多人就说我标题党了，一个 Java 库还来颠覆 Java ？
这可不不是我玩震惊体，打开 VAVR 的官网 ，它的首页就用加粗字体写着 「vavr - turns java™ upside down」
这翻译过来不就是颠覆 Java 吗？
食用指南 阅读本文需要读者对 Java8 的 lambda 语法和常用 API 有一定的了解。
由于是一篇框架的介绍文（地推 ing），为了避免写成官方文档的翻译，本文会有一些约束
 不会穷尽所有特性和 API，仅做抛砖引玉 不会深入到源码细节  关于示例代码，基本会以单元测试的形式给出并保证运行通过
 注：本文使用的 VAVR 版本为 0.10.3，JDK 版本为 11。
 先来个概览
集合，全新的开始 不得不说 Java8 的集合库引入 Stream 以后确实很好用，但也正是因为使用了 Stream，不得不写很多样板代码，反而降低了不少体验。</description>
    </item>
    
    <item>
      <title>真的学不动了：Scala3 与 Type classes</title>
      <link>https://blog.cc1234.cc/posts/typeclasses-2/</link>
      <pubDate>Sun, 19 Jul 2020 10:45:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/typeclasses-2/</guid>
      <description>真的学不动了：Scala3 与 Type classes 引言 Type classes 源自 Haskell，在 Scala 中并没有直接的语法和概念，但却可以借助于强大的隐式系统间接实现，一般称之为 Type classes Pattern。
Type classes pattern 可谓是 Scala 中的屠龙技之一，然而这一招式随着 Scala3 的发布也产生了巨大的变化&amp;hellip;&amp;hellip;
 关于 Type classes 更多内容，可以参考 《真的学不动了: 除了 class , 也该了解 Type classes 了》。
 回顾 Scala2 与 Type classes Scala2 中 Type classes Pattern 有个固定的套路
 基于 trait 和泛型定义 Type class 实现 Type class 实例 定义包含隐式参数的函数  下面用 Scala2 中的 Type classes Pattern 来改造一下经典的 Comparator 接口，相比于上一篇文章，这里的实现会多一些细节。
trait Comparator[T] { def compare(a: T, b: T): Int } object ComparatorInstances { implicit val intComparator = new Comparator[Int] { override def compare(a: Int, b: Int) = a.</description>
    </item>
    
    <item>
      <title>真的学不动了：除了 class , 也该了解 Type classes 了</title>
      <link>https://blog.cc1234.cc/posts/typeclasses-1/</link>
      <pubDate>Wed, 15 Jul 2020 18:45:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/typeclasses-1/</guid>
      <description>真的学不动了： 除了 class , 也该了解 Type classes 了 前言 作为一个 Java 开发者， class 的概念肯定是耳熟能详了，可是在山的另一边还有拥有别样风情的 type classes，但不翻过 Java 这座山，它就始终隔着一层纱。
一个经典的问题 在编程中，经常需要判断两个值是否相等，这就是判等问题， 然而在很长的一段时间内这个问题都没有一个标准的解决方案。
 我这里统一使用 “值” 来代替对象、基本类型等等概念，以便于简化沟通
 在 Java 中，我们可以用 == ，也可以用 equals 来判断值是否相等
public void test() { boolean res = &amp;#34;hello&amp;#34; == &amp;#34;world&amp;#34;; boolean res2 = &amp;#34;hello&amp;#34;.equals(&amp;#34;hello&amp;#34;); boolean res3 = 3 == 3; boolean res4 = 5 == 9; } 熟悉 Java 的同学都知道对于非基础类型， equals 方法的默认实现其实就是调用 == 操作符，而 == 操作比较的是对象的引用地址
public class Object { // .</description>
    </item>
    
    <item>
      <title>多态都不知道，谈什么对象</title>
      <link>https://blog.cc1234.cc/posts/polymorphism/</link>
      <pubDate>Wed, 27 May 2020 23:40:26 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/polymorphism/</guid>
      <description>多态都不知道，谈什么对象 前言 封装、继承、多态作为 OOP 世界的老三样，几乎是必背的关键词。
而在刚学习 Java 的很长一段时间，我对多态的理解一直处理很迷糊的状态，重载是多态吗？泛型是多态吗？继承关系是多态吗？
实际上都是，无论重载、泛型，还是继承关系都是多态的一个具体体现，也被归属为不同的多态分类
 Ad hoc polymorphism（特定多态，也译作特设多态） Parametric polymorphism（参数化多态） Subtyping（子类型多态）  当然不止上面三种分类，像 Scala 就还有另外一种多态分类
 Row polymorphism（行多态）  别被这些名词概念唬住，下面我们就通过代码实例来一一过一遍。
Ad hoc polymorphism（特定多态） 特定多态是由 Christopher Strachey 在 1967 年提出来的，从它的取名我们可以大概猜到，它是针对于特定问题的多态方案，比如：
 函数重载 操作符重载  函数重载指的是多个函数拥有相同的名称，但却拥有不同的实现。
比如下面的函数重载示例，展示了两个名为 print 的 函数，一个打印字符串，一个打印图像。
public void print(String word) { ... } public void print(Image image) { ... } 操作符重载本质上是一个语法糖，实际的体验与函数重载相似，以 Java 中的 + 操作符为例：
 实际上 Java 的 + 不完全算是操作符重载，因为它针对于字符串的操作其实是将 + 转译成了 StringBuilder 来处理的，算是语法糖。</description>
    </item>
    
    <item>
      <title>一次微服务重构总结 </title>
      <link>https://blog.cc1234.cc/posts/xingren-wx-service-refactor/</link>
      <pubDate>Sun, 10 May 2020 23:48:05 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/xingren-wx-service-refactor/</guid>
      <description>一次微服务的技术重构总结 为什么要重构 前段时间接手了一个新的服务，该服务的主要职责是封装「微信公众号」相关的 API ，然后提供整合后的能力给其他业务使用，算是一个很基础的服务。
该服务诞生已有些年头，陆陆续续的功能叠加使得该服务的设计已经背离了初衷，就像下图一样，虽然在努力奔跑着，但早已不堪重负&amp;hellip;&amp;hellip;
那么是时候重构了，引用一下《重构：改善既有代码的设计》中对重构做的事情的描述
 重构很像是在整理代码，你所做的就是让所有东西回到应处的位置上。
代码结构的流失是累积性的。越难看出代码所代表的设计意图，就越难保护其中设计，于是该设计就腐败得越快。
 再划分层 该服务采用的是传统分层架构，分 3 层 共 4 个组件
 Controller：提供 restful API Service：业务核心逻辑 Model：负责与 DB 交互 WX-API: 代理微信的 API 调用  然而在软件的演化中，几个组件的边界却渐渐变得模糊，有融合的趋势
为了指导后续的重构，第一步就是重新划分分层（其实就是还原最开始的设计），当然这里的分层指的是技术分层。
下图就是理想中的分层设计
组件依赖方向是自上而下对的单向依赖，为什么会将第三方服务 WX-API  放在底层呢？
这很好理解，应为要重构的服务就是基于微信提供的能力构建的。
组件模型独立 共享模型对象是造成各个组件耦合的原因之一，那么什么是共享模型对象呢？
WX-API 与微信官方 API 交互时有一套模型对象，Controller 与其他服务交互时也有一套模型对象，如果这两套模型对象实则是复用的同一套，那么这就是共享模型对象。
这里看似复用，实则违背了单一职责，因为从变化的根本原因来说，两者是截然不同的
 WX-API 的变更原因主要和微信官方 API 的升级有关 Controller 的变更原因主要和其他服务或业务的需求相关  这就会导致共享的对象模型会因为不同的原因而产生变化，而这样的变化可能对某个组件产生破坏性的影响，抑或是使得两个组件的耦合性越来越强。
所以就必须得将组件的模型独立出来，不同的模型需要进行转换（Convert)
可以看出 Controller 和 Service 仍然共享了一套模型，这是一种权衡下的抉择，因为过于独立的模型会提高维护的成本。
代码坏味道 代码坏味道指的是任何可能导致深层次问题的代码，这也是重构需要解决的问题。
循环依赖 正常情况下，分层架构并没有限制同层内的依赖关系，但在严格分层模式下，同层内的依赖是被禁止的，这样可以有效的避免循环依赖。
而在该服务中，在 Service 组件内部由于继承的设计而隐式的带来了不少循环依赖，
解决循环依赖的思路很简单，只需要在循环依赖链路中取消一条依赖关系即可。</description>
    </item>
    
    <item>
      <title>Spring Ant-Style Matcher 笔记</title>
      <link>https://blog.cc1234.cc/posts/spring-ant-matcher-note/</link>
      <pubDate>Mon, 04 May 2020 11:40:46 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/spring-ant-matcher-note/</guid>
      <description>Spring Ant-Style Matcher 笔记 在使用 Spring 的时候经常会写路径相关的配置，比如
 @RequestMapping 中配置请求路径 @ComponentScan 中配置包路径 为 Interceptor 配置规则 &amp;hellip;&amp;hellip;  而这些路径的配置规则中，我们经常会看见 、* 等类似于正则表达式的符号，这实际上就是 Spring 的路径匹配规则。
Spring 默认有一个 AntPathMatcher 类用于处理这类路径的规则匹配， 它借鉴了 Ant 的实现（如果你感兴趣的话，可以在点击这里进行了解），这也是为什么称之为 Ant-Style 的原因。
 题外话：Ant 是一个自动化构建工具，最开始是为了解决 Tomcat 的构建问题而诞生的
 Ant 本身是定义了三种匹配规则，而 spring 在此基础之上额外扩展了一种，参考下面的表格
         ? 匹配单个字符   * 匹配 0 个或多个字符   ** 匹配 0 个或多个目录   {spring: [a-z]+} 匹配正则表达式 [a-z]+, 将匹配后的路径作为 spring 的变量    下面的表格展示了一个具体的实例</description>
    </item>
    
    <item>
      <title>HashMap 的细节笔记</title>
      <link>https://blog.cc1234.cc/posts/hashmap-some-detail/</link>
      <pubDate>Mon, 27 Apr 2020 21:19:45 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/hashmap-some-detail/</guid>
      <description>HashMap 的细节笔记 HashMap 的节点转为红黑树以后，树形节点之间是基于什么来比较的呢？ 首先会根据 key 的 Hash 值来进行比较，如果相等的话，会再判断 key 是否实现了 Comparable 接口，如果是的话，可以直接通过 compareTo 方法进行比较。
如果 hash 值相等，而且也没有实现Comparable 接口呢？此时会对 key 对象使用 System.identityHashCode(key) 进行再次 hash 运算，最后再根据新的 hash 值进行比较。
那么 System.identityHashCode 又是什么操作呢？
这是一个 native 的方法，实现的原理也很简单，就是不管你对象有没重写 hashCode 函数，它都只返回对象默认的 hashCode 值。
为什么 HashMap 的链表节点冲突数达到 8 才会转为红黑树？ 在 hashmap 的源码注释中有一段 Implementation notes， 里面有提到具体的决策原因。
虽然红黑树的查询事件复杂度是 logN, 但是红黑树节点的 size 大概是普通节点的 2 倍，而且在插入效率方面，红黑树的插入时间复杂度为 logN, 链表的插入节点时间复杂度是 O (1)。
综上所述，实则是一个时间和空间的决策，那么为什么是 8 呢？
如果 key 的 hash 值分布的足够均匀，几乎不会转换成树形节点。
假设使用随机的 hash 算法，理想情况下，通过泊松分布的概率函数可以计算某个桶位冲突节点达到 K 个的概率，设 λ = 0.</description>
    </item>
    
    <item>
      <title>从 Java8 到 Java11 ： PrettyZoo 开发回顾（模块化在 GUI 中的实践）</title>
      <link>https://blog.cc1234.cc/posts/java-gui-experience/</link>
      <pubDate>Sun, 12 Apr 2020 12:30:37 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/java-gui-experience/</guid>
      <description>从 Java8 到 Java11 ： PrettyZoo 开发回顾（模块化在 GUI 中的实践） 起因 elastic-job-lite 是公司使用的一款定时任务调度框架，该框架将所有的任务调度信息都注册进了 zookeeper 中。
为了方便定位相关的问题，我去网上搜了 zookeeper 相关的图形化客户端，结果没有一款符合自己的需求，于是就干脆自己写一个算了。
 该客户端是去年国庆假期写的，经历了从 Java8 到 Java11 的重构（主要是模块化），该文章主要是对整个过程的一个回顾
 从需求分析到实现 面向用户：zookeeper 用户
软件名称：PrettyZoo
功能：
 节点 CRUD 节点实时同步  交互与原型：
交互分两部，第一步启动页面要求用户输入 zookeeper 的服务地址，连接成功后会跳到节点操作页面
​	技术方案：
 语言采用 Java UI 框架采用 Swing 采用传统的分层架构 Zookeeper Client 采用 Apache Curator  最终实现：
​	不足：
 受限于交互流程，一次只能管理一个 zookeeper server 由于是 Java8，运行需要安装额外的 JRE（或 JDK），影响了受众面 颜值不足 工程质量方面，架构分层不清晰，导致层与层之间相互渗透，随时膨胀为一个 Big Bom  界面与架构的重构规划 重构主要是为了解决上一版的不足，而第一步就是分析产生这些问题的根本原因，再提出对应的解决方案</description>
    </item>
    
    <item>
      <title>架构简谈：从分层到六边形</title>
      <link>https://blog.cc1234.cc/posts/hexagonal-arch/</link>
      <pubDate>Sat, 07 Dec 2019 11:49:06 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/hexagonal-arch/</guid>
      <description>架构演化论：从分层到六边形 分层架构 分层架构模式被认为是所有架构的始祖，该架构将系统从上至下划分为不同的层级，层与层之间定义了明确的依赖限制，按照限制的强弱可以分为严格分层和松散分层两种风格。
不管是严格分层还是松散分层，最基本的规则都一样：上层可以依赖下层，而下层不能依赖上层。
严格分层相对于松散分层的不同点在于是否限制同层依赖和跨层依赖。
分层架构强调层与层之间的边界，明确的边界可以降低耦合，使得职责更加清晰。
在分层中，底层往往比上层稳定，自上而下的依赖就完全符合了稳定依赖原则，如果采用严格分层模式（禁止同层依赖）的话，还可以避免循环依赖。
 David Wheeler: All problems in computer science can be solved by another level of indirection
 然而在现实系统开发中，随着业务的变化，分层架构也不是那么好把控的，主要在于以下几点
  分层会增加，而新加的分层边界往往又不是很明确，这样就形成了一个模糊层
  模糊层可能会形成隐藏的循环依赖
  演进之路 下面以我们常见的三层架构来看看，分层是如何演进成为六边形架构的。
我想 controller =&amp;gt; service =&amp;gt; dao 是每个后端同学都很熟悉的架构了，这是一个很典型的分层架构，并没有什么多说的
当分层和 DIP (依赖倒置原则) 相遇时，会产生另外的化学反应。
controller 和 service 都依赖于 interface，dao 和 service 也都依赖于 interface。
这是一个非常典型的 DIP：抽象不应该依赖于细节，细节应该依赖于抽象
当我们再将这个依赖关系平铺开，就成了这个样子了。多层次关系被拍平了，只剩下内外两层。
这其实就是一个典型的六边形架构了，是不是感觉被糊弄了？
然而这就是事实，当分层架构和 DIP 结合起来的时候，我们已经在使用六边形架构的风格了。
那么难道 DIP + 分层 = 六边形架构 吗？，关于这个问题 Vaughn Vernon 在其著作《实现领域驱动设计》中有过解答：</description>
    </item>
    
    <item>
      <title>Java 模块化系统 Jigsaw</title>
      <link>https://blog.cc1234.cc/posts/java-jigsaw/</link>
      <pubDate>Thu, 24 Oct 2019 21:18:00 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/java-jigsaw/</guid>
      <description>Java 模块化系统 Jigsaw 一览 历史 2017年9月21日 Java9 正式发布，其中最大的变化就是引入了代号为 Jigsaw 的模块化系统（Java Platform Module System，简称 JPMS）。
Java 的模块化系统可以说是一波三折，在 2005 年（Java7） 就已经有提案了（ JSR277 ），但是因为种种历史原因，在一年多后该提案又被取消掉了
直到 2014年，新的提案 JSR376 被提出，Java 的模块化系统才得以重新步入正轨，虽然它迟到了（原计划于 Java8 发布），但并没有缺席。
下图展示了从 JSR376 被提出到实现的各个阶段：
目标 在 JSR376 中，对模块化系统的目标是有非常明确的描述的：
 使用更可靠的配置来描述程序组件之间的依赖关系，并以此替代问题频出的 class-path 组件可以控制其 API 被其他组件的访问性，提供一个更强的封装能力 增加 JavaSE 平台的扩展性，开发人员可以只将他需要的功能模块组装到一个自定义的配置中去 增强平台的完整性，确保平台内部 API 不会被访问 性能提升  实际上最核心的目标是最前面的两点，替代 class-path 和 增强封装性。
 在 Project Jigsaw: Goals &amp;amp; Requirements DRAFT 3 里对于实现目标的描述可能更加通俗易懂一些。
 初次接触 Java9 的模块化系统时，会不自觉的和 Maven、Gradle 等构建工具进行对比，但是实际上两者关注的核心点是不一样的。
模块化系统更注重模块之间的封装性，而构建工具更注重的是依赖管理和项目构建。</description>
    </item>
    
    <item>
      <title>从30分钟到1分钟 - SBT的update耗时优化记录</title>
      <link>https://blog.cc1234.cc/posts/sbt-update-optimize/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/sbt-update-optimize/</guid>
      <description>从30分钟到1分钟 - SBT的update耗时优化记录 前言 公司有项目是基于 Scala 编写的，与之配套的构建工具是 SBT , 它是 Simple Build Tool 的缩写，虽然我觉得它一点也不简单。
这个项目有一个很大的痛点就是刷新依赖 （对应 SBT 的 update）非常之耗时，可以参见下图：
注意图中红框部分，耗时1266秒，近半个小时。在刷新期间资源占用也很高，导致电脑很卡 （风扇还呼呼呼的转，温度蹭蹭蹭的长）。
最关键的是由于依赖的很多服务升级很快 （几乎每天都有升级），所以这个操作每天也会持续很多次，难以想象耗费在这方面的时间是何其之多。
人生苦短，在刷新了几次之后，我再也受不了这漫长的等待时间，于是开始了这漫漫的优化之路。
 正所谓工欲善其事必先利其器
 Round 1: 十八般武艺齐上阵 不知道大家碰见这种问题会怎么做，我反正是二话不说打开 Google 直接搜： SBT 依赖下载慢。
还别说，有共鸣的人还不少， 总结了下几乎都是以下的解决方案
  添加代理 添加国内镜像源   我这肯定不是源的问题啊，我司用的私有仓库，既然私有jar都下载下来了，肯定是走的私有仓库啊。
翻了几页，没有满意的答案，也试了几个方案，也没啥用。
看来还是得自己从问题的根源开始找起啊&amp;hellip;&amp;hellip;
为了保险起见， 我还是先排查一下是不是镜像问题， 项目的 build.sbt 配置文件中是有私有仓库的相关配置项的：
lazy val commonSettings = Seq( //....  // ... 私有仓库  resolvers := {Resolver.url(&amp;#34;xr-ivy-releasez&amp;#34;, new URL(&amp;#34;http://nexus.xxxx.com/repository/ivy-releases/&amp;#34;))(Resolver.ivyStylePatterns) +: resolvers.value}, resolvers := { {&amp;#34;xr-maven-public&amp;#34; at &amp;#34;http://nexus.</description>
    </item>
    
    <item>
      <title>简单聊聊TCP的可靠性</title>
      <link>https://blog.cc1234.cc/posts/tcp-reliability/</link>
      <pubDate>Fri, 30 Aug 2019 13:58:06 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/tcp-reliability/</guid>
      <description>简单聊聊TCP的可靠性 前言  传输控制协议（缩写：TCP）是一种面向连接的、可靠的、基于字节流的传输层通信协议，由 IETF 的 RFC 793 定义。
 TCP 在不可靠的 IP 协议之上实现了可靠性， 从而使得我们不必再去关注网络传输中的种种复杂性，所谓的可靠就是让我们去信任它即可。
信任归信任，可我们还是的得去了解它，知道它为何值得信任，信任主要体现在哪些方面，换句话说就是
 TCP的可靠性是什么 TCP如何实现的可靠性  上面的问题就是本文讨论的核心点
 TCP 的可靠性实则是一个很大的话题，很多细节都值得深究，由于本人水平有限，文中很多描述都没有深入甚至可能有错误，读者若有不同观点，尽可提出。
 什么是可靠性 其实在 RFC 793 的 1.5 Operation 专门对 Reliability （可靠性）做了说明。
总结下来如下
 确保一个进程从其接收缓存中读出的数据流是无损坏，无间隔，非冗余和按序的数据流；即字节流与连接的另一方端系统发送出的字节流是完全相同的
 需要解决的问题 前面说到的可靠性，提到了无损坏，无间隔，非冗余和按序等几个关键词， 而在网络中要实现这些指标，我们都有对应的问题需要去解决。
其中最典型的几个问题如下
  干扰
网络的干扰可能是因为硬件故障导致数据包受到破坏， 也有可能是网络波动导致数据包的某些 bit 位产生了变化
 题外话：这里的干扰并不包含恶意攻击，恶意攻击是属于传输安全的范畴了，比如我们熟知的 SSL/TLS 就是一个成熟的网络传输安全问题的解决方案
 如下图，发送的 111 由于干扰变成了 101
    乱序
发送方连续先后发送两个数据包， 后发送的数据包可能先到达接收方，如果接收方按接收顺序处理数据包，这就会导致接收的数据包与发送的数据包不一致。
造成这样的原因是因为每一个数据包都会根据当时的网络情况选择不同的路由进行传输， 就像多个人开车从上海到北京有很多路线可选，不一定先出发就能先到（我没去过北京，请不要杠我&amp;hellip;&amp;hellip;）
如下图，发送方顺序发送了  A -&amp;gt; B -&amp;gt; C 三个数据包， 然而接收方可能是以 A -&amp;gt; C -&amp;gt; B 这样的顺序接收的报文，很明显 B 和 C 两个个报文的顺序不符合期望，产生了乱序</description>
    </item>
    
    <item>
      <title>Spring的循环依赖</title>
      <link>https://blog.cc1234.cc/posts/spring-circle-reference/</link>
      <pubDate>Thu, 22 Aug 2019 13:30:06 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/spring-circle-reference/</guid>
      <description>Spring的循环依赖 前言  本文最耗时间的点就在于想一个好的标题， 既要灿烂夺目，又要光华内敛，事实证明这比砍需求还要难！
 由于对象之间的依赖关系经常是错综复杂，使用不当会引发很多意想不到的问题， 一个很典型的问题就是循环依赖 （也可以称之为循环引用）。
Spring 为我们提供了依赖注入，并且在某些情景（单例 Bean 的注入）下支持循环依赖的注入
本文的主要目的是分析 Spring 在 Bean 的创建中是如何处理循环依赖的。
我会从循环依赖是什么，以及它的坏处，到最后通过Spring的源码来看它是如何处理这个问题的。
 循环依赖不仅仅是 Spring 的 Bean 之间会产生， 往大了看，系统模块之间会产生循环依赖， 系统与系统之间也会产生循环依赖，这是一个典型的坏味道，我们应该尽量避免。
 什么是循环依赖 循环依赖指的是多个对象之间的依赖关系形成一个闭环。
下图展示了两个对象 A 和 B 形成的一个循环依赖
下图展示了多个对象形成的一个循环依赖
现实中由于依赖层次深、关系复杂等因素， 导致循环依赖可能并不是那么一目了然。
为什么要避免循环依赖 循环依赖会为系统带来很多意想不到的问题，下面我们来简单讨论一下
一、循环依赖会产生多米诺骨牌效应
换句话说就是牵一发而动全身，想象一下平静的湖面落入一颗石子，涟漪会瞬间向周围扩散。
循环依赖形成了一个环状依赖关系， 这个环中的某一点产生不稳定变化，都会导致整个环产生不稳定变化
实际的体验就是
 难以为代码编写测试，因为易变导致写的测试也不稳定 难以重构，因为互相依赖，你改动一个自然会影响其他依赖对象 难以维护，你根本不敢想象你的改动会造成什么样的后果 &amp;hellip;&amp;hellip;  二、循环依赖会导致内存溢出
参考下面的代码
public class AService { private BService bService = new BService(); } public class BService { private AService aService = new AService(); } 当你通过 new AService() 创建一个对象时你会获得一个栈溢出的错误。</description>
    </item>
    
    <item>
      <title>带你破案：文件描述符到底是什么？</title>
      <link>https://blog.cc1234.cc/posts/file-descriptor/</link>
      <pubDate>Tue, 23 Jul 2019 23:34:06 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/file-descriptor/</guid>
      <description>带你破案：文件描述符到底是什么？ 前言 文件描述符在unix系统中几乎无处不在
 网络接口 select、poll、epoll 涉及到文件描述符 IO接口 read、write 也涉及到文件描述符  从形式上来看文件描述就是一个整数，那么我们可不可以更进一步去了解一下呢？
本文打算通过一步一步实验去了解文件描述符到底是什么， 并在最后通过Linux内核相关的源码进行验证。
一个获取文件描述符的实例 我们可以通过 open 系统调用得到一个指定文件的文件描述符。
open 函数需要传入一个文件路径和操作模式， 调用会返回一个整型的文件描述符， 具体方法签名如下
/** * path 代表文件路径 * oflag 代表文件的打开模式，比如读，写等 */ int open(char *path, int oflag, ...) 我们写一段简单的代码来验证一下
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt; int main(int argc, char* argv[]) { // 以只读模式打开 demo.txt 文件 	int fd = open(&amp;#34;demo.txt&amp;#34;, O_RDONLY); if (fd == -1) { perror(&amp;#34;open demo.txt error\n&amp;#34;); return EXIT_FAILURE; } // 打印获取到的文件描述符 	printf(&amp;#34;demo.</description>
    </item>
    
    <item>
      <title>TCP之TCP_NODELAY</title>
      <link>https://blog.cc1234.cc/posts/tcp-nodelay/</link>
      <pubDate>Tue, 26 Mar 2019 14:08:06 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/tcp-nodelay/</guid>
      <description>TCP之TCP_NODELAY 0X00 前言 我们在使用socket（TCP）进行编程时会有很多配置选项, 而TCP_NODEPLAY也正是其中之一， 本文的目的就是研究TCP_NODELAY产生的效果以及其背后的原理。
0X01 TCP_DELAY与Nagle TCP_NODELAY的值为0或1（在有的语言中为true或false）， 当设置为1（true)时即代表着关闭Nagle算法， 反之则代表打开Nagle算法。
Nagle算法由John Nagle发明， 该算法旨在通过减少发送网络包的数量从而提升网络的性能。
那么它是如何减少发送的包数量的呢， 这又得了解作者描述的一个问题 &amp;ndash; “小数据包问题”：
 应用不断的提交小单为的数据， 经常只有1byte大小，而为了发送这1byte的数据， 还需要传输40byte的数据首部包(TCP首部 20byte + IPV4首部 20byte), 从而对网络造成了巨大的开销
 为了解决这个问题，Nagle算法就应运而生了， 下面是该算法的伪码
# MSS代表最大分段大小， 可以理解为TCP愿意接受的数据的字节数最大值 # the window size代表接收窗口的大小 if there is new data to send if the window size &amp;gt;= MSS and available data is &amp;gt;= MSS send complete MSS segment now else # 如果存在未被确认的数据 if there is unconfirmed data still in the pipe # 将该数据加入缓冲， 当接收方一个确认保文返回时就发送该缓冲内的数据 enqueue data in the buffer until an acknowledge is received else send data immediately end if end if end if 我们主要关注Nagle算法对数据合并的方式和时机，以及发送合并数据的时机， 参考下图</description>
    </item>
    
    <item>
      <title>LeetCode-33-Search in rotated sorted array</title>
      <link>https://blog.cc1234.cc/posts/leetcode-33/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/leetcode-33/</guid>
      <description>LeetCode-33-Search in rotated sorted array 题意 假设有一个按升序排列的数组， 现在将其从中间某个位置（未知）将其分成两部分，并交换位置
原数组：[0,1,3,5,6,7,8] 将其分为两部分，索引&amp;lt;4 算一部分， 剩余的为第二部分 将其旋转后得到 [6,7,8,0,1,3,5] 现在你需要在这个旋转后的数组种找寻是否有输入的一个目标值， 如果有就返回它在数组中的索引位置，否则返回-1.
约束条件：
 数组中的值都是不重复的 算法的时间复杂度必须是O(logN)  思路 注意理解两个约束条件（很重要）， 第二个条件要求时间复杂度必须是O(logN), 而在数组查找问题中看见O(logN)我们一般会想到二分查找法（又叫折半查找法）
但是二分查找要求整个输入必须是有序的， 而我们这个输入明显不符合要求。
二分查找一次排除一半的结果集，这是因为能确定结果不在其中，根据这个思路我们还是有希望用二分查找解决这个问题的。
但是我们得先分析旋转后的数组情况， 以便找出一定的规律每次去排除一半的结果集
首先根据题意， 我们得知输入数组最开始是升序的， 只不过要经历一次旋转， 而旋转的位置是未知的。
如果我们给定的旋转位置比0还小的话， 这样数组就不会变化，结构如下图，即 x~y 为升序, 这种情况用正常的二分查找就能解决问题了。
分析 如果给定的旋转位置&amp;gt;=0并且合法，那么数组会被我们分成A,B两部分， 这就会存在以下两种情况
 A.length &amp;gt; B.length A.length &amp;lt;= B.length  下面用图来说明这两种情况， 在图中蓝色区域为A, 红色区域为B
先看第一种情况: A.length &amp;gt; B.length
这种情况下
x &amp;lt; m, n &amp;lt; y, m &amp;lt; n, x &amp;lt; y; 这种情况下使用二分查找计算得到的中间位置midle就落在蓝色区域内</description>
    </item>
    
    <item>
      <title>操作系统之保护模式简谈</title>
      <link>https://blog.cc1234.cc/posts/os-protect-mode/</link>
      <pubDate>Sun, 30 Dec 2018 18:08:06 +0800</pubDate>
      
      <guid>https://blog.cc1234.cc/posts/os-protect-mode/</guid>
      <description>操作系统之保护模式简谈 前言 如果你想学习或者自己尝试写一个操作系统内核，保护模式是你绕不开的一个话题。
这篇文章的主要目的是让你了解保护模式个东西，以及它的作用。
 不会涉及到如何进入保护模式，以及保护模式的一些细节我也会有意略过，
 希望你在读这篇文章的时候，能了解计算机的组成， 对CPU的寄存器体系有一定的了解。
历史 保护模式是CPU的一种运行模式，出现在80286及之后的X86架构的CPU下。
 这里说的CPU运行模式主要体现在CPU在内存寻址的区别。
 在80286之前只有一种运行模式， 由于保护模式和这种模式有非常大的区别， 为了便于区分，便将以前的运行模式称之为实模式， CPU默认是工作在实模式下的。
实模式 最开始的8086最大寻址空间为1MB(即2^20), 但是8086的内部寄存器只有16位，那么如何能够做到1MB的内存寻址呢？Intel采用了以下的方式
 内存地址 = 16位段寄存器 &amp;laquo; 4 + 16位通用寄存器保存的地址偏移
 这样也会出现一个问题：即最终计算的内存地址会大于2^20 , 此时回产生内存回卷
 回卷就是把溢出的最高位1和低16位做加法运算。例如：原本是（1）0100101011000001，回卷就是0100101011000001+1=0100101011000010
 这个就是CPU默认的运行模式&amp;ndash;实模式的最大特点了。
保护模式 80286之后出现的保护模式，不仅仅改变了内存的寻址方式，还增加了存储器保护，标签页系统以及硬件支持的虚拟内存等特性。
为了兼容， 该模式默认是关闭的， 要由程序（通常是系统内核）主动切换。
为什么要有保护模式呢？因为80286的内存寻址空间达到16MB， 而80386更是达到了4GB, 实模式没法满足寻址的要求了。
下面我们就来讲一下保护模式是如何实现以上特性的。
在我们切换到保护模式之前我们要准备一个数据结构**全局描述符表**， 它的本质是一个数组， 数组中的每一个元素称为**全局描述符**， 这是一个64位的数据结构。
 数据结构看着有点怪是不是？这其实是历史原因
 全局描述符包含可访问的内存的基址， 最大长度， 以及其他的一些权限位。
这个全局描述符的地址被放在了一个称之为 GDTR的寄存器中
现在的段寄存器存储的就是全局描述符表的索引， 我们一般称之为段选择子
 实际上段选择子的高13位存储的是索引， 低3位用来存储和权限相关的bit, 可以参考下图
 这样的话我们的寻址方式就变成了以下流程了
 从GDTR取得全局描述符表的地址 从段选择子取得索引 idx， 然后用 idx * 64 + 全局描述符的地址 得到 一个全局描述符的地址（前面我们讲过一个描述符是64bit的数据结构） 从全局描述符我们可以拿到内存的BaseAddress, 用BaseAddress + 16位通用寄存器的偏移 就可以得到最终的物理内存地址  注意， 我有意跳过了相关的权限检查的流程， 参考下图(目前得到的线性地址-Linear address 就是物理内存地址)</description>
    </item>
    
  </channel>
</rss>
